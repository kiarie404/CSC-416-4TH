<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Developer Documentation</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="setting_things_up.html"><strong aria-hidden="true">1.</strong> Setting Things Up</a></li><li><ol class="section"><li class="chapter-item expanded "><div><strong aria-hidden="true">1.1.</strong> Setting up the compiler</div></li><li class="chapter-item expanded "><a href="setting_up_LLD_linker.html"><strong aria-hidden="true">1.2.</strong> Setting up the linker</a></li><li class="chapter-item expanded "><a href="setting_up_qemu.html"><strong aria-hidden="true">1.3.</strong> Setting up the Riscv Virtual environment</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">1.4.</strong> Setting up the Build automation tool</div></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">2.</strong> Setting Up Communications</div></li><li class="chapter-item expanded "><a href="setting_up_memory_allocation.html"><strong aria-hidden="true">3.</strong> Setting Up Memory Allocation</a></li><li class="chapter-item expanded "><a href="setting_up_memory_virtualization_and_access_management.html"><strong aria-hidden="true">4.</strong> Setting Up Memory Virtualization and access_management</a></li><li class="chapter-item expanded "><a href="setting_up_processes.html"><strong aria-hidden="true">5.</strong> Setting up Processes</a></li><li class="chapter-item expanded "><a href="handling_interrupts_and_traps.html"><strong aria-hidden="true">6.</strong> Handling interrupts and Traps</a></li><li class="chapter-item expanded "><a href="definitions_and_theories.html"><strong aria-hidden="true">7.</strong> Definitions and Theories</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="theory_on_the_linker.html"><strong aria-hidden="true">7.1.</strong> The linker</a></li><li class="chapter-item expanded "><a href="theory_on_Qemu.html"><strong aria-hidden="true">7.2.</strong> Qemu</a></li><li class="chapter-item expanded "><a href="fragmentation_issues.html"><strong aria-hidden="true">7.3.</strong> fragmentation_issues</a></li><li class="chapter-item expanded "><a href="memory_tracking_mechanisms.html"><strong aria-hidden="true">7.4.</strong> Memory Tracking Mechanisms</a></li><li class="chapter-item expanded "><a href="theory_on_MMU_implementation_in_riscv.html"><strong aria-hidden="true">7.5.</strong> Theory on MMU implementation in Riscv</a></li></ol></li><li class="chapter-item expanded "><div><strong aria-hidden="true">8.</strong> Miscellenious</div></li><li><ol class="section"><li class="chapter-item expanded "><a href="errors.html"><strong aria-hidden="true">8.1.</strong> Error Numbers</a></li><li class="chapter-item expanded "><a href="measuring_software_performance.html"><strong aria-hidden="true">8.2.</strong> Measuring Performance of software</a></li><li class="chapter-item expanded "><a href="importing_variables_from_the_linker_script.html"><strong aria-hidden="true">8.3.</strong> Importing variables from the Linker script</a></li><li class="chapter-item expanded "><a href="GNU_assembly_macros.html"><strong aria-hidden="true">8.4.</strong> GNU assembly macros</a></li></ol></li><li class="chapter-item expanded "><a href="setting_up_wasm_runtime.html"><strong aria-hidden="true">9.</strong> Setting Up Wasm Runtime</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Developer Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h2 id="setting-things-up"><a class="header" href="#setting-things-up">Setting Things Up</a></h2>
<p>Under this chapter, we intend to answer the following 3 questions :</p>
<ol>
<li>What are we setting up?</li>
<li>Why are we setting up those things?</li>
<li>How are we seting up those things?</li>
</ol>
<h3 id="what-are-we-setting-up"><a class="header" href="#what-are-we-setting-up">What are we setting up?</a></h3>
<p>We are setting up a <strong>development toolchain</strong>, <strong>RISCV virtual environment</strong> and a <strong>no-std Rust file</strong>.</p>
<h4 id="the-development-toolchain"><a class="header" href="#the-development-toolchain">The development Toolchain</a></h4>
<p>A toolchain is a group of software tools that typically get used together...a chain of tools...
In OS Development, the name toolchain usually refers to the combination of the compiler, linker, debugger and a bunch of programs that help in inspecting files. This toolchain gets used to convert source code into a format that can run on an execution <em>environment</em>.</p>
<p>An execution environment is a place where a software program can run. It provides the necessary resources, like the operating system and libraries, that the program needs to function. Examples of execution enviroments include: Bare metal, Browsers, Virtual Machines, Operating systems and Containers.</p>
<p>The toolchain in our case will consist of the following tools :</p>
<ol>
<li>The Rust Nightly Compiler with a riscv64gc-unknown-none-elf backend</li>
<li>linker : Rust-lld</li>
<li>Binutils </li>
<li>Make</li>
</ol>
<p>To our luck, we do not have to install all these elements seperately. There exists compact toolchains :</p>
<ol>
<li>LLVM Riscv toolchain</li>
<li>The GNU Riscv Toolchain</li>
</ol>
<h4 id="why-we-need-the-toolchain"><a class="header" href="#why-we-need-the-toolchain">Why we need the toolchain</a></h4>
<p>We will have two kinds of source code files in our project : Rust source files and RISCV-Assembly files. Both of these types of files need to be turned into object files. Afterwards, those object files need to get linked together into a single executable file.</p>
<p>We can go about this process of creating a single executable file in two ways:
1. Method 1 
We can compile the Rust files seperately from the Assembly files. Afterwords we can combine the resultant object files using a linker to form a single executable.
2. Method 2
We can embed the assembly code into the Rust source code. That way, we only need one compilation, we will only need to compile the asm_embedded Rust files. This method seems more of plug and play. The disadvantage is that we will always have to re-compile every file each time we change anything in any source file. But this is not really a problem. Modern compilers are Fast. This is a more user friendly method. Trading off negligible compile time over a user-friendly build and configuration process is by far a very good choice.</p>
<pre><code>    Moreover, the rust compiler comes with its own inbuilt LLVM linker, rust-lld. That means that once we hit compile, we get the executable file output. One click, and all the build process runs inbuilt; from compiling rust files, to compiling assembly files, to creating a riscv-compliant executable file
</code></pre>
<h4 id="the-rust-llvm-compiler-and-targets"><a class="header" href="#the-rust-llvm-compiler-and-targets">The Rust LLVM compiler and Targets</a></h4>
<h4 id="the-linker"><a class="header" href="#the-linker">The Linker</a></h4>
<p><em><strong>references</strong></em></p>
<ul>
<li><a href="https://lld.llvm.org/">The LLD official Page</a></li>
<li><a href="https://nnethercote.github.io/perf-book/compile-times.html">Linking in Rust</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-the-linker"><a class="header" href="#setting-up-the-linker">Setting up the linker</a></h1>
<p>As earlier mentioned, the Rust compiler comes with an inbuilt linker. 
Each target comes with its own configured linker</p>
<p>So by default we do not need a linker script. But as for our case, we are going to do define the memory addresses various sections of the elf file will point to. We are going to manipulate virtual memory addresses in our assembly code. So instead of letting the linker execute its default memory assignation, we define it ourselves.</p>
<p>We would not wish to work with a blackbox.</p>
<p>Here is the Linker script :</p>
<pre><code class="language-bash">
/*
  riscv is the name of the architecture that the linker understands
  for any RISC-V target (64-bit or 32-bit).

  We will further refine this by using -mabi=lp64 and -march=rv64gc
*/
OUTPUT_ARCH( &quot;riscv&quot; )

/*
We're setting our entry point to a symbol
called _start which is inside of boot.S. This
essentially stores the address of _start as the
&quot;entry point&quot;, or where CPU instructions should start
executing.

In the rest of this script, we are going to place _start
right at the beginning of 0x8000_0000 because this is where
the virtual machine and many RISC-V boards will start executing.
*/
ENTRY( _start )

/*
The MEMORY section will explain that we have &quot;ram&quot; that contains
a section that is 'w' (writeable), 'x' (executable), and 'a' (allocatable).
We use '!' to invert 'r' (read-only) and 'i' (initialized). We don't want
our memory to be read-only, and we're stating that it is NOT initialized
at the beginning.

The ORIGIN is the memory address 0x8000_0000. If we look at the virt
spec or the specification for the RISC-V HiFive Unleashed, this is the
starting memory address for our code.

Side note: There might be other boot ROMs at different addresses, but
their job is to get to this point.

Finally LENGTH = 128M tells the linker that we have 128 megabyte of RAM.
The linker will double check this to make sure everything can fit.

The HiFive Unleashed has a lot more RAM than this, but for the virtual 
machine, I went with 128M since I think that's enough RAM for now.

We can provide other pieces of memory, such as QSPI, or ROM, but we're
telling the linker script here that we have one pool of RAM.
*/
MEMORY
{
  ram   (wxa!ri) : ORIGIN = 0x80000000, LENGTH = 128M
}

/*
PHDRS is short for &quot;program headers&quot;, which we specify three here:
text - CPU instructions (executable sections)
data - Global, initialized variables
bss  - Global, uninitialized variables (all will be set to 0 by boot.S)

The command PT_LOAD tells the linker that these sections will be loaded
from the file into memory.

We can actually stuff all of these into a single program header, but by
splitting it up into three, we can actually use the other PT_* commands
such as PT_DYNAMIC, PT_INTERP, PT_NULL to tell the linker where to find
additional information.

However, for our purposes, every section will be loaded from the program
headers.
*/
PHDRS
{
  text PT_LOAD;
  data PT_LOAD;
  bss PT_LOAD;
}

/*
We are now going to organize the memory based on which
section it is in. In assembly, we can change the section
with the &quot;.section&quot; directive. However, in C++ and Rust,
CPU instructions go into text, global constants go into
rodata, global initialized variables go into data, and
global uninitialized variables go into bss.
*/
SECTIONS
{
  /*
    The first part of our RAM layout will be the text section.
	Since our CPU instructions are here, and our memory starts at
	0x8000_0000, we need our entry point to line up here.
  */
  .text : {
	  /* 
	    PROVIDE allows me to access a symbol called _text_start so
		I know where the text section starts in the operating system.
		This should not move, but it is here for convenience.
		The period '.' tells the linker to set _text_start to the
		CURRENT location ('.' = current memory location). This current
		memory location moves as we add things.
	  */

    PROVIDE(_text_start = .);
	/*
	  We are going to layout all text sections here, starting with 
	  .text.init. The asterisk in front of the parentheses means to match
	  the .text.init section of ANY object file. Otherwise, we can specify
	  which object file should contain the .text.init section, for example,
	  boot.o(.text.init) would specifically put the .text.init section of
	  our bootloader here.

	  Because we might want to change the name of our files, we'll leave it
	  with a *.

	  Inside the parentheses is the name of the section. I created my own
	  called .text.init to make 100% sure that the _start is put right at the
	  beginning. The linker will lay this out in the order it receives it:

	  .text.init first
	  all .text sections next
	  any .text.* sections last

	  .text.* means to match anything after .text. If we didn't already specify
	  .text.init, this would've matched here. The assembler and linker can place
	  things in &quot;special&quot; text sections, so we match any we might come across here.
	*/
    *(.text.init) *(.text .text.*)

	/*
	  Again, with PROVIDE, we're providing a readable symbol called _text_end, which is
	  set to the memory address AFTER .text.init, .text, and .text.*'s have been added.
	*/
    PROVIDE(_text_end = .);
	/*
	  The portion after the right brace is in an odd format. However, this is telling the
	  linker what memory portion to put it in. We labeled our RAM, ram, with the constraints
	  that it is writeable, allocatable, and executable. The linker will make sure with this
	  that we can do all of those things.

	  &gt;ram - This just tells the linker script to put this entire section (.text) into the
	         ram region of memory. To my knowledge, the '&gt;' does not mean &quot;greater than&quot;. Instead,
			 it is a symbol to let the linker know we want to put this in ram.

	  AT&gt;ram - This sets the LMA (load memory address) region to the same thing. LMA is the final
	           translation of a VMA (virtual memory address). With this linker script, we're loading
			   everything into its physical location. We'll let the kernel copy and sort out the 
			   virtual memory. That's why &gt;ram and AT&gt;ram are continually the same thing.

	  :text  - This tells the linker script to put this into the :text program header. We've only
	           defined three: text, data, and bss. In this case, we're telling the linker script
			   to go into the text section.
	*/
  } &gt;ram AT&gt;ram :text
   /*
     The global pointer allows the linker to position global variables and constants into
	 independent positions relative to the gp (global pointer) register. The globals start
	 after the text sections and are only relevant to the rodata, data, and bss sections.
   */
   PROVIDE(_global_pointer = .);
   /*
     Most compilers create a rodata (read only data) section for global constants. However,
	 we're going to place ours in the text section. We can actually put this in :data, but
	 since the .text section is read-only, we can place it there.

	 NOTE: This doesn't actually do anything, yet. The actual &quot;protection&quot; cannot be done
	 at link time. Instead, when we program the memory management unit (MMU), we will be
	 able to choose which bits (R=read, W=write, X=execute) we want each memory segment
	 to be able to do.
   */
  .rodata : {
    PROVIDE(_rodata_start = .);
    *(.rodata .rodata.*)
    PROVIDE(_rodata_end = .);
	/*
	   Again, we're placing the rodata section in the memory segment &quot;ram&quot; and we're putting
	   it in the :text program header. We don't have one for rodata anyway.
	*/
  } &gt;ram AT&gt;ram :text

  .data : {
	/*
	   . = ALIGN(4096) tells the linker to align the current memory location (which is
	   0x8000_0000 + text section + rodata section) to 4096 bytes. This is because our paging
	   system's resolution is 4,096 bytes or 4 KiB.
	*/
    . = ALIGN(4096);
    PROVIDE(_data_start = .);
	/*
	   sdata and data are essentially the same thing. However, compilers usually use the
	   sdata sections for shorter, quicker loading sections. So, usually critical data
	   is loaded there. However, we're loading all of this in one fell swoop.
	   So, we're looking to put all of the following sections under the umbrella .data:
	   .sdata
	   .sdata.[anything]
	   .data
	   .data.[anything]

	   ...in that order.
	*/
    *(.sdata .sdata.*) *(.data .data.*)
    PROVIDE(_data_end = .);
  } &gt;ram AT&gt;ram :data

  .bss : {
    PROVIDE(_bss_start = .);
    *(.sbss .sbss.*) *(.bss .bss.*)
    PROVIDE(_bss_end = .);
  } &gt;ram AT&gt;ram :bss

  /*
     The following will be helpful when we allocate the kernel stack (_stack) and
	 determine where the heap begnis and ends (_heap_start and _heap_start + _heap_size)/
	 When we do memory allocation, we can use these symbols.

	 We use the symbols instead of hard-coding an address because this is a floating target.
	 As we add code, the heap moves farther down the memory and gets shorter.

	 _memory_start will be set to 0x8000_0000 here. We use ORIGIN(ram) so that it will take
	 whatever we set the origin of ram to. Otherwise, we'd have to change it more than once
	 if we ever stray away from 0x8000_0000 as our entry point.
  */
  PROVIDE(_memory_start = ORIGIN(ram));
  /*
     Our kernel stack starts at the end of the bss segment (_bss_end). However, we're allocating
	 0x80000 bytes (524 KiB) to our kernel stack. This should be PLENTY of space. The reason
	 we add the memory is because the stack grows from higher memory to lower memory (bottom to top).
	 Therefore we set the stack at the very bottom of its allocated slot.
	 When we go to allocate from the stack, we'll subtract the number of bytes we need.
  */
  PROVIDE(_stack = _bss_end + 0x80000);
  PROVIDE(_memory_end = ORIGIN(ram) + LENGTH(ram));

  /* 
     Finally, our heap starts right after the kernel stack. This heap will be used mainly
	 to dole out memory for user-space applications. However, in some circumstances, it will
	 be used for kernel memory as well.

	 We don't align here because we let the kernel determine how it wants to do this.
  */
  PROVIDE(_heap_start = _stack);
  PROVIDE(_heap_size = _memory_end - _stack);
}

</code></pre>
<p>Now that our linker script is ready, we need to configure our build settings in the cargo file:<br />
Add the following line to cargo.toml.  That way, we notify the linker about the path to the linker script</p>
<pre><code class="language-bash">[build]
target = &quot;riscv64gc-unknown-none-elf&quot;
rustflags = ['-Clink-arg=-Tsrc/lds/virt.lds']
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-the-riscv-virtual-environment"><a class="header" href="#setting-up-the-riscv-virtual-environment">Setting up the Riscv Virtual environment</a></h1>
<p><a href="./theory_on_Qemu.html">Crude</a></p>
<p>We will be using the <a href="https://www.qemu.org/docs/master/system/target-riscv.html">Qemu RISC-V System emulator</a> to emulate a RISCV-CPU microcontroller. </p>
<h4 id="how-to-install-qemu-riscv-system-emulator-on-linux-mint"><a class="header" href="#how-to-install-qemu-riscv-system-emulator-on-linux-mint">How to install Qemu RISCV system Emulator on Linux-Mint</a></h4>
<p>At the command type</p>
<pre><code class="language-bash">sudo apt install qemu-user
sudo apt install qemu-system-misc
</code></pre>
<h4 id="qemu-configurations"><a class="header" href="#qemu-configurations">Qemu Configurations</a></h4>
<p>For QEMU’s RISC-V system emulation, you must specify which board model you want to emulate with the -M or --machine option; there is no default. In our case we will emulate the <a href="https://www.qemu.org/docs/master/system/riscv/virt.html">‘virt’ Generic Virtual Platform </a>as our target board model</p>
<p>When using the sifive_u or virt machine there are three different firmware boot options: </p>
<ol>
<li>-bios default - This is the default behaviour if no -bios option is included. This option will load the default OpenSBI firmware automatically. The firmware is included with the QEMU release and no user interaction is required. All a user needs to do is specify the kernel they want to boot with the -kernel option </li>
<li>-bios none - QEMU will not automatically load any firmware. It is up to the user to load all the images they need. </li>
<li>-bios --file - Tells QEMU to load the specified file as the firmware.</li>
</ol>
<p>We will use the following Qemu configurations ;</p>
<pre><code class="language-bash">// we define some variables 
QEMU=qemu-system-riscv64  // we are using the Riscv Qemu emulator. qemu-system-riscv64 is a variable containing the path to the QEMU executable
MACH=virt                 // we will target the Virt Riscv Machine 
CPU=rv64                  // we will use a 64-bit CPU
CPUS=4                    // The Board will have 4 CPUs... 4 HARTS
MEM=128M                  // The RAM memory will be 128 MBs
DRIVE=hdd.dsk             // This is the path to our virtual harddrive

$(QEMU) -machine $(MACH) 
        -cpu $(CPU) 
        -smp $(CPUS)     // specifies the number of CPUs to emulate
        -m $(MEM)        // specifies the amount of RAM in MBs 
        -nographic       // disables graphical output, so QEMU runs in a terminal window.
        -serial mon:stdio // connects the virtual machine motherboard's serial port to the host's system terminal. Ie, our Linux terminal. This enables us to use the terminal as a console to the virtual machine.
        -bios none       // we not depend on any firmware becaue our machine is virtual. We can just direclty load the OS image to memory. 
        -kernel $(OUT)  // This specifies the path to the kernel image file
        -drive if=none,format=raw,file=$(DRIVE),id=attic // explained below
        -device virtio-blk-device,scsi=off,drive=attic     // explained below
</code></pre>
<pre><code class="language-bash">-drive if=none,format=raw,file=$(DRIVE),id=attic
</code></pre>
<p><strong>'if=none'</strong> meant that Qemu should not create an interface between the hard drive and the Kernel image. An example of an interface is SATA interface.</p>
<p>'<strong>format=raw</strong>' means that the hard drive image should consist of raw bytes to represent data on the disk. The disk should no have extra metadata or compressions.
Other possible values for the format option include:</p>
<ul>
<li>qcow2: This is the default format for disk images in QEMU/KVM, and it supports features like compression, snapshots, and encryption.</li>
<li>mdk: This is a format used by VMware virtualization software.</li>
<li>vpc: This is a format used by Microsoft Virtual PC.</li>
<li>raw: This is similar to format=raw, but it includes a 512-byte header that specifies the disk geometry and other information.</li>
</ul>
<p>The choice of disk image format depends on the specific needs of your virtualization environment. For example, if you need to support snapshots or compression, you would likely choose qcow2. If you need to import or export the image to another virtualization platform, you may need to choose a format that is compatible with that platform.</p>
<pre><code class="language-bash">-device virtio-blk-device,scsi=off,drive=attic
</code></pre>
<p><strong>'-device'</strong> is a Qemu command for attaching new devices to the motherboard of the virtual machine.</p>
<p><strong>virtio-blk-device,scsi=off,drive=attic</strong> implies that we are adding a block device that adheres to VIRTIO protocol. '<strong>scsi=off</strong>' disables the SCSI (Small Computer System Interface), this is because we intend to write a custom virtio block driver. '<strong>drive=attic</strong>' specifies the Identifier of the new device that is being attached.</p>
<h4 id="creating-a-virtual-hard-disk"><a class="header" href="#creating-a-virtual-hard-disk">Creating a virtual hard disk</a></h4>
<p>In the configurations above, it was specified that a virtual hard disk would get attached to the motherboard. It was specified that its path would be ./hdd.dsk</p>
<p>To create this hard disk we use a tool called <a href="https://man7.org/linux/man-pages/man8/losetup.8.html">Losetup</a>. This tool converts a normal text file into a virtual block hard drive.</p>
<p>Losetup creates Loop devices. A loop device is a file that emulates a block device.</p>
<p>Losetup comes pre-installed in any standard linux distribution. To check its documentation, type this in the terminal:</p>
<pre><code class="language-bash">man losetup
</code></pre>
<p>To create a virtual disk within your development working dierctory, write the following command in your terminal: </p>
<pre><code class="language-bash">dd if=/dev/zero of=hdd.dsk count=32 bs=1M  
</code></pre>
<p>where : </p>
<ul>
<li>'<strong>if=/dev/zero</strong>: This option specifies the input file to use for the dd command. In this case, the input file is /dev/zero, which is a special file that produces an endless stream of zeroes when read.</li>
<li><strong>of=hdd.dsk</strong>: This option specifies the output file to create for the dd command. In this case, the output file is called hdd.dsk.</li>
<li><strong>count=32</strong>: This option specifies the number of blocks to copy from the input file to the output file. In this case, 32 blocks of data will be copied.</li>
<li><strong>bs=1M</strong>: This option specifies the block size to use for the dd command. In this case, the block size is 1 megabyte (1M).</li>
</ul>
<p>An alternative set of commands would be :</p>
<pre><code class="language-bash">fallocate --length 32M hdd.dsk  // create a new file called hdd.dsk and allocate to it 32 MB
sudo losetup /dev/loop0 hdd.dsk // convert hdd.dsk into a  virtual hard drive whose mount point is at /dev/loop0
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><p>RAM memory management</p>
<ul>
<li>
<p>Our elf file gets loaded into the RAM (128 Mbs) by the elf_file loading system found in Qemu.</p>
</li>
<li>
<p>Or program starts off at 0x8000_0000</p>
</li>
<li>
<p>The RAM takes the following format in our case : </p>
<ul>
<li>ORIGIN = 0x80000000, LENGTH = 128MBs</li>
<li>text section : _text_start --&gt; _text_end</li>
<li>Global Pointer
<ul>
<li>rodata section : _rodata_start --&gt; _rodata_end    :   length is variable...just continuous : position </li>
<li>data section   : _data_start --&gt; _data_end        :   length is variable...just continuous </li>
<li>bss section    : _bss_start --&gt; _bss_end          :   length is variable...just continuous</li>
</ul>
</li>
<li>Kernel Stack
<ul>
<li>length : 524 KiB</li>
<li>start  : _bss_end</li>
<li>end    : _bss_end + 524 KiB in hexadecimal</li>
</ul>
</li>
<li>Heap
<ul>
<li>length : Total memory - Memory occupied by all the above sections.</li>
<li>start  : Kernel end</li>
<li>end    : End of memory ie (ORIGIN + LENGTH)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="under-the-heap"><a class="header" href="#under-the-heap">UNDER THE HEAP</a></h4>
<p>we have the following segments:</p>
<ol>
<li>An array of descriptors</li>
<li>A countiguous allocation of pages</li>
</ol>
<ul>
<li>
<p>When creating the memory management system of the OS, we have to take care of 3 responsibilities:</p>
<ol>
<li>Find a way to allocate and deallocate physical heap memory byte_wise.</li>
<li>Find a way to allocate and deallocate physical heap memory page_wise.</li>
<li>Find a way to create a safe interface between programs and the memory itself
<ul>
<li>This interface will :
<ol>
<li>Abstract the physical memory by providing virtual pages and virtual bytes</li>
<li>Make sure the access rights of each page is defined in a procee_wise fashion.</li>
<li>Provide a special API to the Kernel. Provide a different API to the normal processes.</li>
</ol>
</li>
</ul>
</li>
</ol>
</li>
<li>
<p>Why is the Kernel getting a special API? What is contained in the API? </p>
</li>
<li>
<p>We could have used the hardware assisted memory management scheme in Riscv... but why are we not?  Write you tradeoffs here future James</p>
<ul>
<li>The SV39 system is hard to understand for me</li>
</ul>
</li>
<li>
<p>Why have we not used the sv48 or the bare metal system? When would they have been appropriate? What tradeoffs did we consider?</p>
</li>
</ul>
<h3 id="page-grained-physical-memory-allocations"><a class="header" href="#page-grained-physical-memory-allocations">Page Grained Physical memory allocations</a></h3>
<ul>
<li>
<p>It means that when free memory is either allocated or deallocated... it is done in a pagewise manner. ie The address of a new empty page is returned when an allocation is needed.</p>
</li>
<li>
<p>A page in our system is 4096 bytes long. ie 4 KiB</p>
</li>
<li>
<p>A page allocation is less precise that a byte allocation. Allocating a whole page(4096 bytes) in a single command is better than allocoting bytes 4096 times. It means you need to execute 4096 byte-wise commands in order to do what a single page command would have done.</p>
</li>
<li>
<p>Also building a management system for bytes is harder than building the same sytem for pages. There are more items to manage in a byte-wise system... for one page that you need to manage... you need to manage 4085 more items if you had taken the byte route.</p>
</li>
<li>
<p>However, developers writing memory efficient systems may need a byte grained system ready for action in serious cases.</p>
</li>
</ul>
<p>So in our page allocation system we need to achieve the following :</p>
<ol>
<li>Keep track of all free pages</li>
<li>Keep track of all allocated pages</li>
<li>Keep track of pages that have been used together</li>
<li>Provide a function that receives a request of allocating certain number of contiguous pages... and it returns the address of the first page of the available contiguous pages</li>
<li>Provide a function that receives an address of occupied pages and completely frees them.</li>
</ol>
<p>We could implement our tracking syste using one of the following methods :</p>
<ol>
<li>
<p>Treating each page as a linked list node.
<img src="../images/raw/linked_list_representation_of_heap.jpg" alt="linked_list_representation_of_heap" />
At the top of the Node, we have a pointer to the next node. So we create 2 lists... used nodes and unused nodes</p>
<ul>
<li>This method helps because there is no need for contiguous allocation of pages. This consequently means that we will not have <a href="./fragmentation_issues.html">fragmentation issues</a></li>
<li>However this method has a couple of disadvantages :
<ul>
<li>It takes more space. This is because you have to store the address of the next node + information as to whether it is the last block or not.</li>
<li>The fact that memory allocated is not contiguous means referencing memory gets compicated. You cannot simply use straight foward offsets. You have to use virtual offsets that adds upon performance inefficiency.</li>
<li>The pages are dirty. The top part of the page has the address of the next node. If a process want to read or write to the page, it has to consider that some information contained in the page is useless to it. And when a couple of pages are read, the process has to filter out the next_address and start concatenating necessary data. This is unnecessary work</li>
<li>There is no direct access within the linked list... you have to traverse it from the beginning each time. Thi is a very huge DEFFIFIENCY because we are dealing with the RAM. Ram daa access is expected to be fast. If we has used an array or some tree structure, the CPU would have had faster access speeds.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>We could use a 2-bit bitmap : THis is the fastest and most memory efficient method
<img src="../images/raw/bitmap_representation_of_heap_memory.jpg" alt="bitmap_representation_of_heap_memory" /></p>
</li>
<li>
<p>We could use a bunch of descriptors. This would be the same as that of a bitmap execution. It is just that each descriptor takes 1 byte to describe a page while in the bitmap uses only 2 bits to describe a page (empty, taken, first, last)
<img src="../images/raw/descriptor_representation_of_heap_memory.jpg" alt="descriptor_representation_of_heap_memory" /></p>
</li>
</ol>
<p>More discissions about memory tracking are found <a href="./memory_tracking_mechanisms.html">here</a></p>
<p>We opt to use descriptors because :</p>
<ul>
<li>Even though Bitmapping is more memory efficient than using descriptors...Using descriptors is simpler to implement. Using Bitmapping would cut our memory usage by 75%. But for now...this is a learning project.... simplicity is our first priority. </li>
<li>Using a Linked List has only one advantage ; it solves the fragmentation issue. Other than that it is memory inefficient, performance inefficient and hard to implement. If we implement inodes on top of descriptors... fragmentation problems in the descriptor method becomes solved.</li>
</ul>
<h4 id="so-what-is-this-descriptor-method-of-tracking"><a class="header" href="#so-what-is-this-descriptor-method-of-tracking">So what is this descriptor method of tracking?</a></h4>
<p>A descriptor is an 8byte enum that Describes the status of a page. The value of the enum can be one of the following values :
- page is empty
- page has been taken and it's the first node for a certain contiguous allocation
- page has been taken and it's neither the first nor the last node for a certain contiguous allocation
- page has been taken and it's the last node for a certain contiguous allocation</p>
<ol>
<li>We divide the heap into pages that are aligned to 4KiB.</li>
<li>We segment the heap into : 
<ul>
<li>Pages used to store descriptors  - segment 1</li>
<li>Pages used to store data         - segment 2</li>
</ul>
</li>
<li>Under the segment 1, we store an array of descriptors. The number of descriptors is equal to the number of pages that can fit in the segment 2 of the heap.</li>
</ol>
<h4 id="the-allocation-method"><a class="header" href="#the-allocation-method">The allocation method</a></h4>
<p>algorithm : alloc
inputs to alloc algorithm : the number of free pages required (required_pages)
Outputs to alloc algorithm : the address of the first page of a contiguous block of free pages (starter)
main goal : return an address to the first page of a free contiguous set of pages  : A RESULT VALUE (pointer/ error)</p>
<p>Steps:</p>
<ol>
<li>Confirm that the number of required pages is more than zero.
<ol>
<li>If number is zero or less
<ol>
<li>throw an <a href="./errors.html">Error M1</a></li>
<li>return the error to the calling function.</li>
</ol>
</li>
<li>If the number is more than zero... continue to step 2</li>
</ol>
</li>
<li>Traverse the array of descriptors found in the heap</li>
<li>Try to Find a block of contiguous free pages
<ol>
<li>If you find a block... skip to step 4</li>
<li>If you traverse the whole array and you do not find space ... skip to step 5</li>
</ol>
</li>
<li>Do the folowing :
<ul>
<li>update the descriptors that represent the block</li>
<li>return the pointer to the first page of the block</li>
</ul>
</li>
<li>Do the following
<ul>
<li>return an <a href="./errors.html">error_M2</a> indicating that there is no free contiguous space.</li>
</ul>
</li>
</ol>
<h4 id="the-de-allocation-method"><a class="header" href="#the-de-allocation-method">THe de-allocation method</a></h4>
<p>algorithm : dealloc
inputs to dealloc algorithm : the address of the first page of a contiguous block of pages that needs to be freed (starter)
Outputs to dealloc algorithm : The Result Type (Ok/Error)
main goal : deallocate </p>
<p>Steps:</p>
<ol>
<li>Check if the starter address is valid or not.
<ul>
<li>If the starter address is a null pointer... go to step 2</li>
<li>If the starter address is an out of range address... go to step 3</li>
<li>If the starter address is a valid address...go to step 4</li>
</ul>
</li>
<li>Return a Result_Error showing that the process tried to deallocate a null pointer : Error_M3</li>
<li>Return a Result_Error showing that the process tried to deallocate a non-existent memory location : Error_M4</li>
<li>Loop through the allocated block page by page :
<ul>
<li>For every page...
<ul>
<li>clear the data by zero-ing the bytes within the page</li>
<li>Change the status of the corresponding descriptor to 'empty'</li>
</ul>
</li>
</ul>
</li>
<li>After the loop, return a successful message Result (ok) type</li>
</ol>
<h4 id="testing-this-module"><a class="header" href="#testing-this-module">Testing this module</a></h4>
<p>This module does 3 tasks. So we need to test all the 3 tasks.</p>
<ol>
<li>Task 1 was : abstracting the heap into descriptors and pages.</li>
<li>Task 2 was : writing a function that returns the address of the first page associated with a free block of contiguous pages</li>
<li>Task 3 was : writing a function that frees a contiguous block of contiguous pages</li>
</ol>
<h5 id="test-1--testing-task-1-"><a class="header" href="#test-1--testing-task-1-">Test 1 : Testing task 1 :</a></h5>
<p>In this test, we compare preconfigured data that we calculated in theory and hope that our alocation function produces similar data.<br />
Confirm if the following values are similar:</p>
<ul>
<li>
<p>The heap_start address</p>
</li>
<li>
<p>The heap_end address</p>
</li>
<li>
<p>The number of data pages</p>
</li>
<li>
<p>The number of descriptors</p>
</li>
<li>
<p>number of descriotors == number of data pages</p>
</li>
<li>
<p>Confirm that all the addresses of each page are a divisible of 4096</p>
</li>
<li>
<p>Confirm that all descriptors are initially set to 'empty'</p>
</li>
</ul>
<h5 id="test-2--testing-task-2-the-allocating-function"><a class="header" href="#test-2--testing-task-2-the-allocating-function">Test 2 : Testing Task 2, the allocating function</a></h5>
<ul>
<li>confirm that submitting a zero to the function returns the appropriate Error </li>
<li>Confirm that submitting a value more than the number of pages found in a &lt;128 MB heap will give the appropriate error.</li>
<li>confirm that certain descriptor change after allocation : we should have a &quot;first&quot; and &quot;end&quot; and possibly a middle. But not 2 consecutive &quot;firsts&quot; or &quot;ends&quot;.</li>
</ul>
<h5 id="test-3--testing-task-3-the-deallocation-function"><a class="header" href="#test-3--testing-task-3-the-deallocation-function">Test 3 : Testing Task 3, the deallocation function</a></h5>
<ul>
<li>confirm that submitting a null pointer yields the appropriate error</li>
<li>confirm that submitting a pointer that is not within the heap range yields the appropriate error</li>
<li>Confirm that all the data pages are indeed zeroed after deallocation and that they contain no garbage data or residue data.</li>
<li>Confirm that all descritors involved in the deallocation process are updated to 'empty'</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><p>In the previous section we did the following :</p>
<ol>
<li>We abstracted the heap memory as pages that are associated to descriptors.</li>
<li>We provided the allocation and deallocation functions</li>
</ol>
<p>In the previous module we were dealing with Physical addresses. We were executing code while the CPU was in Machine mode. This means that the memory management unit was turned off. Our code was referencing live physical addresses. eg memory_start = 0x8000000</p>
<p>In this module we want to abstract the physical RAM. We will virtualize all the memory addresses of the RAM. In real life the RISCV board provides a hardware implementation of a Memory management unit. The MMU can operate in Bare Mode, SV39 mode or SV48 mode.</p>
<p>Here is a theory discussion of the <a href="./theory_on_MMU_implementation_in_riscv.html">theory on MMU implementation of Riscv</a>.</p>
<p>As discussed in the theory :</p>
<ol>
<li>For us to use the MMU hardware, we need to activate it, choose a mode and finally switch our cpu from machine mode to either Supervisor mode or Usermode.</li>
<li>We need to map all the linker_initialized memory locations.</li>
<li>When mapping the heap, we need to set aside kernel heap and user_program heap.  Isolating the two is good for security... and modularity. It means the kernel will always have a dedicated heap and that it will not compete for space with the rest of the user programs.</li>
<li>We need to implement an access control mechanism.</li>
<li>Each process should get a dedicated virtual address space</li>
</ol>
<p>We will satisfy the above needs as follows :</p>
<h4 id="develop-a-virtual-mmu-instead-of-using-the-physical-mmu"><a class="header" href="#develop-a-virtual-mmu-instead-of-using-the-physical-mmu">Develop a Virtual MMU instead of using the physical MMU</a></h4>
<p>We will not use the MMU hardware. Meaning that our kernel will continue executing in machine mode. Our user programs will also execute in machine mode. Instead of using the MMU hardware, we will implement a virtual MMU that works in SV39 mode.
Using the MMU hardware could have given us many advantages :
Performance: Physical MMUs provide faster and more efficient memory access than virtual MMUs. This is because physical MMUs are implemented in hardware, which makes them faster than software-based virtual MMUs. The physical MMU has caches that make memory translation process much faster.</p>
<pre><code>Security: Physical MMUs provide better security than virtual MMUs. Physical MMUs can be used to implement hardware-based memory protection, which prevents unauthorized access to memory. This is not possible with virtual MMUs because they rely on software to implement memory protection.

Reliability: Physical MMUs are more reliable than virtual MMUs. Since physical MMUs are implemented in hardware, they are less prone to software bugs and errors, which can cause system crashes or data corruption.

Scalability: Physical MMUs are more scalable than virtual MMUs. As the size of physical memory increases, physical MMUs can be easily expanded to accommodate the increased memory, whereas virtual MMUs may require significant changes to the operating system and software.
</code></pre>
<p>With all this advantages, it is obvious that using the hardware MMU is the right choice. So why use a virtual MMU?<br />
Learning and understanding how the hardware MMU works in detail takes time. It will be faster to just understand how the MMU works from a high level and implement it in software form. Most of the details involved around understanding the hardware MMU are centered around space optimization. As a result, there is much bitmasking and predefined procedures to follow.</p>
<p>For now, for the sake of implementation time, using the virtual MMU is the way to go.<br />
We will borrow SV39 mode concepts.</p>
<h4 id="major-tasks"><a class="header" href="#major-tasks">Major Tasks</a></h4>
<ol>
<li>Abstract the SATP register</li>
<li>Abstract the root table, parent table and child tables</li>
<li>Abstract the entries
<ul>
<li>branch and leaf entries</li>
</ul>
</li>
<li>Define functions to Map the Linker defined memory locations</li>
<li>Define functions to Map kernel heap addresses.</li>
<li>Define functions to Map user heap addresses</li>
<li>Define function to translate Linker defined memory locations</li>
<li>Define function to translate kernel heap addresses</li>
<li>Define function to translate user heap addresses</li>
<li>Define the API of the MMU
<ul>
<li>The exposed functions</li>
<li>The exposed structs</li>
<li>The success responses and error messages {this means you have to program }</li>
</ul>
</li>
</ol>
<h4 id="pseudocode"><a class="header" href="#pseudocode">Pseudocode</a></h4>
<ol>
<li>Abstract the SATP register</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="setting-up-processes"><a class="header" href="#setting-up-processes">Setting Up processes</a></h1>
<p>we have 2 kinds of processes that we need to set up :</p>
<ol>
<li>Kernel processes</li>
<li>User Processes</li>
</ol>
<p>Each process has a process structure. A process structure is a data structure that represents the state and attributes of a running process in an operating system. It typically contains information such as the process ID (PID), the program counter (PC), memory allocation details, and other resources associated with the process.</p>
<p>The process structure is used by the operating system code to manage and control the execution of processes on the system. It allows the operating system to keep track of the resources used by each process, schedule them for execution, and provide them with access to system resources such as I/O devices and memory.</p>
<p>Under the process structure, we have the following pieces of information :</p>
<ol>
<li>The process ID</li>
<li>The process state</li>
<li>The program counter</li>
<li>The address to the process stack</li>
<li>The TrapFrame</li>
<li>The process data section</li>
</ol>
<h4 id="1-the-process-state"><a class="header" href="#1-the-process-state">1. The Process state</a></h4>
<p>The process state indicates whether a process is currently executing, waiting for input/output (I/O), waiting for a resource, or in some other state.<br />
In our case, the process state will indicate whether the process is : Running, Waiting, Sleeping or Dead.</p>
<p><strong>A Running process</strong> is a process that is currently getting executed by the CPU. To be precise, the program counter is referencing addresses found within the process text section.</p>
<p><strong>A Sleeping process</strong> is a process that voluntarily stopped and is taking a timeout in order to wait for its turn to use the CPU.</p>
<p><strong>A waiting Process</strong> is a process that has involuntarily stopped because a certain condition has not been met. For example an I/O operation.</p>
<p><strong>A dead process</strong> is a process that is non_existent or it has finished executing and has been terminated by the operating system. The PCB for a terminated process is typically removed from memory. </p>
<h4 id="the-trap-frame"><a class="header" href="#the-trap-frame">The Trap Frame</a></h4>
<p>undone</p>
<h4 id="the-process-stack"><a class="header" href="#the-process-stack">The process stack</a></h4>
<p>undone</p>
<h4 id="initializing-a-process"><a class="header" href="#initializing-a-process">Initializing a process</a></h4>
<ol>
<li>Pass a kernel function address to Process_constructor, let's call this address k_func</li>
<li>create an empty process structure</li>
<li>Fill the process structure with the following default values :
<ul>
<li>Navigate into the Trapframe and set all values within the trapframe to zero</li>
<li>make the address pointing to the stack to point to a null pointer</li>
<li>make program counter point to a null address</li>
<li>make the process state to be dead</li>
<li>make the pid point to an invalid address</li>
</ul>
</li>
<li>Allocate a couple of pages </li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h3 id="what-is-an-interrupt"><a class="header" href="#what-is-an-interrupt">what is an interrupt?</a></h3>
<h3 id="what-is-a-trap"><a class="header" href="#what-is-a-trap">What is a trap?</a></h3>
<h3 id="how-is-a-trap-handled"><a class="header" href="#how-is-a-trap-handled">How is a trap handled?</a></h3>
<h3 id="how-is-an-interrupt-handled"><a class="header" href="#how-is-an-interrupt-handled">How is an interrupt handled?</a></h3>
<h2 id="risc-v-interrupt-system"><a class="header" href="#risc-v-interrupt-system">RISC-V Interrupt System</a></h2>
<p>The riscv system allows you to handle traps in all the CPU modes : usermode, supervisor mode and machine mode.<br />
But our system will handle all OS interrupts and traps in machine mode..</p>
<p>When an interrupt happens, the cpu : </p>
<ol>
<li>updates the mcause register</li>
<li>updates the mepc register</li>
<li>updates mtval register </li>
<li>saves the context of the current program </li>
<li>calls the interrupt handling function.<br />
The address of the interrupt handling function is stored in the mtvec register (Machine Trap Vector). A vector is a fancy word for saying &quot;pointer to a function&quot;</li>
</ol>
<p>We will use Direct mode of handling interrupts, we wil not use the vectored approach.<br />
Below is the the structure of the mtvec register :<br />
<img src="../images/mtvec.png" alt="mtvec register layout" /></p>
<p>THe mcause register store information about :</p>
<ol>
<li>The type of interrupt (whether it is synchronous or asynchronous)  0 == Synchronous, 1 == Asynchronous</li>
<li>The code specifying the cause of interrupt eg code 12 == instruction page fault</li>
</ol>
<p>we will handle rhe flow of interrupt handling using the following files :</p>
<ol>
<li>boot.s</li>
<li>trap.s</li>
<li>trap.rs</li>
</ol>
<h3 id="boots"><a class="header" href="#boots">boot.s</a></h3>
<p>boot.s contains the assembly code that </p>
<ol>
<li>Initializes CPU registers and makes the mecp register point to the enntry point of the kernel code ie kmain. suxh that if we call mret... the kernel code starts executing.</li>
<li></li>
</ol>
<h2 id="rust-function-to-handle-interrupts"><a class="header" href="#rust-function-to-handle-interrupts">Rust function to handle Interrupts</a></h2>
<p>inputs : 
1. mcause : helps us determine the type and code of the interrupt
2. mepc   : helps us determine the latest value of the program counter
3. mtval  : some error handling functions need the matval eg in a page fault, the mtval registe contains the address of the faulty page
4. </p>
<p>Output : the program counter to the next instruction after the error handler has done its thing</p>
<p>Steps :
1. Check if the interrupt is synchronous or asynchronous. We divide this way for modularities sake. Also it is a standard convention.
- If the interrupt is synchromous, go to step 2
- If the interrupt is asynchromous, go to step 6
2. Extract the cause code from the mcause
3. Make the return address point to the mepc... since this was the latest program counter
4. use a switch to call specific error handling functions based on <a href="handling_interrupts_and_traps.html#table-x">table x</a>
5. return the updated program counter
6. Extract the cause code from the mcause
7. Make the return address point to the mepc... since this was the latest program counter
8. use a switch to call specific error handling functions based on <a href="handling_interrupts_and_traps.html#table-y">table y</a>
9. return the updated program counter</p>
<h6 id="table-x"><a class="header" href="#table-x">Table x</a></h6>
<p><img src="../images/mcause_synchronous_interrupts.png" alt="" /></p>
<h6 id="table-y"><a class="header" href="#table-y">Table y</a></h6>
<p><img src="../images/mcause_asynchronous_interrupts.png" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="definitions-and-theories"><a class="header" href="#definitions-and-theories">Definitions and Theories</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-linker-1"><a class="header" href="#the-linker-1">The linker</a></h1>
<h4 id="what-is-a-linker"><a class="header" href="#what-is-a-linker">What is a linker?</a></h4>
<p>A linker is a program that links object files generated by a compiler into an executable or shared library. It resolves external symbols and relocations, and generates the final output file.</p>
<h4 id="what-are-external-symbols"><a class="header" href="#what-are-external-symbols">What are External symbols?</a></h4>
<p>External symbols are variables that get declared in one object file, but they also get used in another different object file. For example, I may declare a global variable 'X' in a header file. If I reference this header file in another file (eg main.rs) and use variable X... that means X has become an external symbol.</p>
<h4 id="what-does-resolving-exernal-symbols-mean"><a class="header" href="#what-does-resolving-exernal-symbols-mean">What does resolving Exernal symbols mean?</a></h4>
<p>In the context of the linker, resolving External symbols means finding the actual memory location or address of a symbol that is referenced by another module, and updating the reference in the module that uses the symbol to point to the correct memory location.</p>
<h4 id="what-is-relocation"><a class="header" href="#what-is-relocation">What is relocation?</a></h4>
<p>Relocation is the act of changing the memory address pointed to by a variable. In the case of a linker, after it has resolved all external symbols, it changes the memory addresses of those external symbols and makes them point to different memory addresses that were specified by the linking script.</p>
<p>So the relocation process adjusts the addresses of symbols in an object file to reflect their final location in memory. In this case, we mean virtual memory addresses... NOT Physical memory addresses.</p>
<h4 id="what-is-this-linking-script"><a class="header" href="#what-is-this-linking-script">What is this linking script?</a></h4>
<p>A linker script is a text file that provides additional instructions to the linker about how to link the input files. It can specify the layout of the output file or the order in which the input files should be linked.</p>
<p><a href="go_back?">crude</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="qemu"><a class="header" href="#qemu">Qemu</a></h1>
<p>QEMU is a generic and open source machine emulator and virtualizer.</p>
<p>A machine emulator is a software program that simulates the behaviour of another computer or another computing system. For example you may simulate the behavior of a quantum computer on a convetional computer.</p>
<p>A virtualizer is a program that abstracts an underlying system. The underlying system can be anything : Bare metal cpu, a hard disk, an operating system... anything.</p>
<p>QEMU can be used in several different ways. The most common is for System Emulation, where it provides a virtual model of an entire machine (CPU, memory and emulated devices) to run a guest OS. In this mode the CPU may be fully emulated, or it may work with a hypervisor such as KVM, Xen, Hax or Hypervisor.Framework to allow the guest to run directly on the host CPU.</p>
<p>The second supported way to use QEMU is User Mode Emulation, where QEMU can launch processes compiled for one CPU on another CPU. In this mode the CPU is always emulated.</p>
<p>In our project, we will use Qemu as a <a href="https://www.qemu.org/docs/master/system/target-riscv.html">Riscv System Emulator</a>. </p>
<div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><div style="break-before: page; page-break-before: always;"></div><p>undone</p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="under-the-memory-management"><a class="header" href="#under-the-memory-management">Under the Memory Management</a></h3>
<ol>
<li>The allocation function was requested to allocate no Pages. This is like going to the shop and telling a shopkeeper to sell you nothing. There might be a problem with the calling function.</li>
<li>error_M2
<ul>
<li>Reason for Error :The RAM has no contiguous free pages that are equal to the number of pages requested. </li>
<li>Possible causes  : 
<ul>
<li>The heap in the RAM has space... it is just that the available space is not contiguous. The available space is scatterd in fragmnets.</li>
<li>The RAM is fully occupied and there is no extra space.</li>
</ul>
</li>
<li>Possible solutions :
<ul>
<li>Defragment the heap</li>
<li>Add more RAM to the machine</li>
<li>Close other processes so that some space in the RAM can be freed</li>
</ul>
</li>
</ul>
</li>
<li>Error_M3
<ul>
<li>Reason for error : The program tried to de-allocate a null pointer. You cannot de-allocate nothing. </li>
<li>Possible causes  : The program written by the programmer tried to free an null pointer. Fix your code brah</li>
<li>Possible solutions : Fix your code... ha ha</li>
</ul>
</li>
<li>Error_M4 
<ul>
<li>Error              : The program tried to access and deallocate an address that is not found within the heap section</li>
<li>Possible causes    : The address is not within the address ranges specified by the linker script</li>
<li>Posible solutions  : Find an address that is within the range : _heap_start and _heap_end. Moreover, the address should be within the segment of the heap where data_pages are stored.</li>
</ul>
</li>
<li>Error_M5</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><p>You can check this out : <a href="https://docs.wasmtime.dev/examples-profiling.html">here</a> it is a way of measuring wasm app performance on Linux.<br />
This can act as a gate to other performance measurers</p>
<p>All the Best future James, I leave it in your capable hands</p>
<div style="break-before: page; page-break-before: always;"></div><p>One of the responsibilities of the linker is to resolve global symbols. What that means is that you can reference a global variable or global function that was used in a seperate crate or object file... and the linker will take care of validating and linking those references.</p>
<p>In our project, we had declared and initialized some memory positions in the linker script. We need to reference those memory position variables in our Rust code.</p>
<p>To do that, we make those variables global using the lds.s file... For example, to make _heap_size global, we do something like this :</p>
<pre><code class="language-asm">.global HEAP_SIZE
HEAP_SIZE: .dword _heap_size
</code></pre>
<p>Afterwards we import thos global variables into Rust using the <a href="https://doc.rust-lang.org/std/keyword.extern.html">'extern' keyword</a></p>
<p>Considering that Rust does not trust or know the implementations of variables and functions that have been borrowed from other languages, we are required to enclose the borrowed code in 'unsafe' blocks.</p>
<p>Unsafe variables are unreliable... so we enclose them in safe getter functions as shown below :</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Constants recieved from the linker script
extern &quot;C&quot;
{
    static TEXT_START: usize;
    static TEXT_END: usize;
    static RODATA_START: usize;
    static RODATA_END: usize;
    static DATA_START: usize;
    static DATA_END: usize;
    static BSS_START: usize;
    static BSS_END: usize;
    static KERNEL_STACK_START: usize;
    static KERNEL_STACK_END: usize;
    static HEAP_START: usize;
    static HEAP_END: usize;
}

/// Get the text start address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn text_start() -&gt; usize
{
	unsafe { TEXT_START }
}

/// Get the text end address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn text_end() -&gt; usize
{
	unsafe { TEXT_END }
}

/// Get the rodata start address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn rodata_start() -&gt; usize
{
	unsafe { RODATA_START }
}

/// Get the rodata end address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn rodata_end() -&gt; usize
{
	unsafe { RODATA_END }
}

/// Get the data start address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn data_start() -&gt; usize
{
	unsafe { DATA_START }
}

/// Get the data end address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn data_end() -&gt; usize
{
	unsafe { DATA_END }
}

/// Get the bss start address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn bss_start() -&gt; usize
{
	unsafe { BSS_START }
}

/// Get the bss end address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn bss_end() -&gt; usize
{
	unsafe { BSS_END }
}

/// Get the stack start address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn stack_start() -&gt; usize
{
	unsafe { KERNEL_STACK_START }
}

/// Get the stack end address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn stack_end() -&gt; usize
{
	unsafe { KERNEL_STACK_END }
}

/// Get the heap start address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
pub fn heap_start() -&gt; usize
{
	unsafe { HEAP_START }
}

/// Get the heap end address as a usize
/// Safety: Because this value should have been read properly from the linker
/// script, this is safe
<span class="boring">pub fn heap_end() -&gt; usize
</span>{
	unsafe { HEAP_END }
<span class="boring">}
</span><span class="boring">}</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><p>undone</p>
<div style="break-before: page; page-break-before: always;"></div><h4 id="random"><a class="header" href="#random">Random</a></h4>
<p>Random :</p>
<ul>
<li>wasm is an Instruction set because it specifies a set of instructions that can be understood by a virtual machine. The same way Riscv assembly instructions can be understood by a Riscv CPU. Riscv is an instruction set too.</li>
<li>In computer science abtraction solves everything. When you want to standardize somthing... just virtualize accurately it and leave individual implementations to other people.</li>
<li>Now to enable code to run on any machine... wasm group created a binary language/ an assembly language for a virtual machine. There are different implementations of this virtual machine. Those different implementations are called web assembly runtimes </li>
</ul>
<p>From Chat Gpt :
Web Assembly (WASM) was designed to enable code to run on any machine, regardless of the underlying hardware or operating system. To achieve this, the WASM group created a binary format that can be executed by a virtual machine. This binary format serves as an assembly language for the virtual machine and is designed to be compact and efficient.</p>
<pre><code>There are different implementations of the Web Assembly virtual machine, each designed to run on a specific platform or operating system. These implementations are sometimes referred to as &quot;Web Assembly runtimes&quot; or &quot;WASM runtimes.&quot; Examples of popular Web Assembly runtimes include the V8 engine used in Google Chrome and Node.js, the SpiderMonkey engine used in Firefox, and the Wasmtime runtime developed by the Bytecode Alliance.
</code></pre>
<p>These web assembly runtimes run on top of other systems. Eg on top of bare metal hardware, or in the browser, on top of operating systems.</p>
<h3 id="questions"><a class="header" href="#questions">Questions</a></h3>
<p>Which wasm runtimes can Run on bare metal?
- wasmer
- wasmi
- wasmtime
- wamr</p>
<p>Which one are we choosing?<br />
we will work with wasmtime or wasmer. They have very good documentation. They are up to date with WASM post-mvp features. They are maintained by core members of the Bytecode alliance. They are majorly written in Rust Programming Language. They have a mature Rust integration too.</p>
<p>Why not wasmi?</p>
<ul>
<li>wasmi does not have a comprehensive documentation in comparison to wasmer or wasmtime.</li>
<li>wasmi is implemented as an interpreter. An intepreter in the embedded space is inappropriate.</li>
</ul>
<p>Why not wamr?</p>
<ul>
<li>It is written in C.</li>
</ul>
<h4 id="on-wasmtime"><a class="header" href="#on-wasmtime">On wasmtime</a></h4>
<ul>
<li>
<p>Wasmtime can be used both as a crate or a cmd-utility.</p>
</li>
<li>
<p>we will use it as a crate. We will embed it in core Rust code.</p>
</li>
<li>
<p>Someone should be able to take a .wasm file that is wasi compliant, load it in the OS as a user program and wait for output.</p>
</li>
<li>
<p>You will not be able to install wasmtime itself as a user program in our OS... unless you install it as a .wasm fileS</p>
</li>
<li>
<p>Our focus will not be on the commandline utility aspect.</p>
</li>
</ul>
<h5 id="creating-wasm-files-from-highlevel-languagesrust-and-running-them"><a class="header" href="#creating-wasm-files-from-highlevel-languagesrust-and-running-them">Creating wasm files from highlevel languages(Rust) and running them.</a></h5>
<ul>
<li>Install wasm32-wasi target. Install wasmtime-CLI. run .wasm files using wasmtime CLI commands</li>
<li>But you can also go through the embedded way</li>
</ul>
<h5 id="the-embedded-wayour-ticket-to-heaven"><a class="header" href="#the-embedded-wayour-ticket-to-heaven">The Embedded Way...our ticket to heaven</a></h5>
<p>You can instantiate a wasm module inside Rust code using the crate ; <a href="https://docs.rs/wasmtime/8.0.0/wasmtime/index.html">wasmtime</a>.<br />
An instantiated module is a webassembly file that has been compiled and has been stored in memory... ready to be executed.<br />
Now let us breakdown that statement: 
- Now the Engine has an internal compiler that takes in a raw file and outputs an optimized target-specific binary.(eg x86, Riscv)
- We use this engine to first compile our .wat file into a .wasm file
- You can use the default compiler configurations or you can pass a Config struct to adjust the compiler's behaviour. Soe of the things that you can adjust include : (a full list is <a href="https://docs.rs/wasmtime/8.0.0/wasmtime/struct.Config.html">here</a>)
- Target architecture
- Enable or disable outputting certain Performance Profiling metadata
- Enable or disable outputting certain Debugging metadata that might be used by 3rd party debugging tools.
- Disable code optimization or adjust the level of code optimization done by the compiler.
- Enabling or disabling specific WebAssembly features. For example, the bulk_memory feature allows using bulk memory operations, while the simd feature allows using SIMD instructions 
- Now 'storing in memory' means  that the webassembly runtime understood the memory requirements of the module and allocated the appropriate data structures and space within the memory that was asigned to the host application in the RAM.
- Now from this definitions, an instance means 'a process' and the wasmtime runtime acts as the CPU.
- So just like a normal process, the wasm instances are self contained and isolated. Self contained means that they have their own memory and all the imports were satisfied. Isolated means that the host application only communicates through imports and exports.
- The host application code gets executed by the real CPU while the wasm instantiated module gets executed by the wasm runtime. *The WebAssembly runtime translates the WebAssembly code into machine code that can be executed by the CPU of the host machine.  so even though both codes get executed by the host CPU... they take different paths before they get there.</p>
<p>A Store is a collection of WebAssembly instances and host-defined state.<br />
The store is responsible for managing the state of instantiated modules. This state includes things like the module's memory, global variables, and table. The state of the module can be modified and accessed by calling its exported functions, but it is not directly accessible from outside the module or from other instantiated modules</p>
<p>We need to :</p>
<ol>
<li>import the wasmtime crate</li>
<li>Compile the .wat module
<ul>
<li>Instantiate an Engine : &quot;a compiler + a manager of instantiated modules under it&quot;</li>
<li>configure the compiler found within the Engine</li>
<li>Compilation is done using something called an engine's compiler. It returns a compiled module called wasmtime::Module</li>
</ul>
</li>
<li>Define a store</li>
<li>Define all the host functions that are required by the wasm  module</li>
<li>Function Wrap those host-defined functions</li>
</ol>
<p>The WebAssembly page size, currently 64 kilobytes.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>

        <!-- Livereload script (if served using the cli tool) -->
        <script>
            const wsProtocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
            const wsAddress = wsProtocol + "//" + location.host + "/" + "__livereload";
            const socket = new WebSocket(wsAddress);
            socket.onmessage = function (event) {
                if (event.data === "reload") {
                    socket.close();
                    location.reload();
                }
            };

            window.onbeforeunload = function() {
                socket.close();
            }
        </script>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </body>
</html>
